# Hanan Ather

I am a Member of Technical Staff at the Centre for AI Research and Excellence (CAIRE) at [Statistics Canada](https://www.statcan.gc.ca/en/start).
I build full-stack AI systems and the evals that make them safe to deploy in confidential-data settings.

My current focus is AI security, applied mechanistic interpretability, and uncertainty quantification for AI systems.

- Won [International Association for Official Statistics Young Statisticians Prize 2025](https://iaos-isi.org/ysp/) for a Bayesian framework integrating LLMs with uncertainty quantification.
- MATS 10.0 Scholar in [Neel Nanda](https://www.matsprogram.org/mentor/neel)â€™s stream ([MATS Program](https://www.matsprogram.org/)).
- I contribute to guidance and governance work with [UNECE](https://statswiki.unece.org/), [G7 GovAI](https://impact.canada.ca/en/challenges/g7-govAI), and the [International Statistical Institute](https://www.isi-web.org/).

## Projects

- [Fine-tune Auditor (SAE affordances)](https://github.com/hananather/codex_mcp_finetune_auditor): adds SAE-based model diffing to fine-tuning auditing agents, exposed via an MCP tool server for end-to-end agentic audits ([paper](https://arxiv.org/abs/2510.16255), [MCP](https://github.com/hananather/codex_mcp_finetune_auditor#mcp-server), [base code](https://github.com/safety-research/finetuning-auditor)).
- [Probability Lab](https://www.probability-lab.com): interactive probability and statistics learning platform ([code](https://github.com/hananather/probability), [course context](https://catalogue.uottawa.ca/en/search/?P=MAT%202377)).
- [Reinforcement Learning Labs](https://hananather.com/rl-labs/): a 6-part notebook series ([notebooks](https://github.com/hananather/hananather/tree/main/rl-labs), [master thesis](https://hananather.com/website_docs/master-thesis-deep-reinforcement-learning.pdf)).
